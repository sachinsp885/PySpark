{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20995d59",
   "metadata": {},
   "source": [
    "## PySpark ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is file reading in PySpark?\n",
    "# PySpark allows you to read data from different file formats (CSV, JSON, Parquet, Avro, ORC, text, etc.) into a DataFrame.\n",
    "# You can then perform transformations and actions on this DataFrame.\n",
    "# It’s similar to pandas.read_csv() but distributed and optimized for big data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c40466",
   "metadata": {},
   "source": [
    "CSV READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CSV\") \\\n",
    "    .getOrCreate()\n",
    "df_csv = spark.read.format('csv').option('inferSchema',True)\\\n",
    "    .option('header',True)\\\n",
    "    .load('C:/Git files/My git files/PySpark/files/sales_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3866843f",
   "metadata": {},
   "source": [
    "JSON READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72149299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JSON\") \\\n",
    "    .getOrCreate()\n",
    "df_json = spark.read.format('json').option('inferSchema', True)\\\n",
    "    .option('header', True)\\\n",
    "    .option('multiline', True)\\\n",
    "    .load('C:/Git files/My git files/PySpark/files/sales_data.json')\n",
    "\n",
    "for i in df_json.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6032f4",
   "metadata": {},
   "source": [
    "## Reading Parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dcba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.parquet(\"path/to/file.parquet\")\n",
    "df_parquet.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9498c972",
   "metadata": {},
   "source": [
    "### Reading Text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df64215",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = spark.read.text(\"path/to/file.txt\")\n",
    "df_text.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff25f8",
   "metadata": {},
   "source": [
    "### Options and Schema\n",
    "#### You can specify schema manually for faster reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"country\", StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read.csv(\"path/to/file.csv\", header=True, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d148bddc",
   "metadata": {},
   "source": [
    "#### 7️⃣ Reading multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi = spark.read.csv(\"path/to/folder/*.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9c505",
   "metadata": {},
   "source": [
    "##### 8️⃣ Reading from cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b8094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 example\n",
    "df_s3 = spark.read.csv(\"s3a://bucket-name/path/file.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b853a79",
   "metadata": {},
   "source": [
    "| File Type | Function             | Notes                             |\n",
    "| --------- | -------------------- | --------------------------------- |\n",
    "| CSV       | `spark.read.csv`     | `header=True`, `inferSchema=True` |\n",
    "| JSON      | `spark.read.json`    | Nested JSON supported             |\n",
    "| Parquet   | `spark.read.parquet` | Columnar, fast                    |\n",
    "| Text      | `spark.read.text`    | Each line → row                   |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
