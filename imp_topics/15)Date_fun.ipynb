{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c5ed02",
   "metadata": {},
   "source": [
    "# DATE FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb7219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ“… PySpark Date Functions â€“ Complete Table\n",
    "\n",
    "| Function                       | Type           | Description                          | Example                                      |\n",
    "| ------------------------------ | -------------- | ------------------------------------ | -------------------------------------------- |\n",
    "| `current_date()`               | Current        | Returns today's date                 | `df.select(current_date())`                  |\n",
    "| `current_timestamp()`          | Current        | Returns current timestamp            | `df.select(current_timestamp())`             |\n",
    "| `date_format(col, fmt)`        | Format         | Converts date to custom format       | `df.select(date_format(\"dt\", \"yyyy-MM-dd\"))` |\n",
    "| `to_date(col)`                 | Conversion     | Converts string to date              | `df.select(to_date(\"str_date\"))`             |\n",
    "| `to_timestamp(col)`            | Conversion     | Converts string to timestamp         | `df.select(to_timestamp(\"str_ts\"))`          |          |\n",
    "| `year(col)`                    | Extract        | Extracts year                        | `df.select(year(\"dt\"))`                      |\n",
    "| `month(col)`                   | Extract        | Extracts month number                | `df.select(month(\"dt\"))`                     |\n",
    "| `dayofmonth(col)`              | Extract        | Extracts day of month                | `df.select(dayofmonth(\"dt\"))`                |\n",
    "| `dayofyear(col)`               | Extract        | Extracts day of year                 | `df.select(dayofyear(\"dt\"))`                 |\n",
    "| `dayofweek(col)`               | Extract        | Extracts weekday (1=Sun)             | `df.select(dayofweek(\"dt\"))`                 |\n",
    "| `weekofyear(col)`              | Extract        | ISO week number                      | `df.select(weekofyear(\"dt\"))`                |\n",
    "| `hour(col)`                    | Extract (time) | Extract hour from timestamp          | `df.select(hour(\"ts\"))`                      |\n",
    "| `minute(col)`                  | Extract (time) | Extract minute                       | `df.select(minute(\"ts\"))`                    |\n",
    "| `second(col)`                  | Extract (time) | Extract second                       | `df.select(second(\"ts\"))`                    |\n",
    "| `add_months(col, n)`           | Arithmetic     | Adds n months to date                | `df.select(add_months(\"dt\", 2))`             |\n",
    "| `date_add(col, n)`             | Arithmetic     | Adds n days                          | `df.select(date_add(\"dt\", 5))`               |\n",
    "| `date_sub(col, n)`             | Arithmetic     | Subtracts n days                     | `df.select(date_sub(\"dt\", 5))`               |\n",
    "| `datediff(end, start)`         | Arithmetic     | Days between two dates               | `df.select(datediff(\"end_dt\", \"start_dt\"))`  |\n",
    "| `months_between(end, start)`   | Arithmetic     | Months difference                    | `df.select(months_between(\"d1\", \"d2\"))`      |\n",
    "| `next_day(col, day)`           | Utility        | Returns next given weekday           | `df.select(next_day(\"dt\", \"Monday\"))`        |\n",
    "| `last_day(col)`                | Utility        | Last day of month                    | `df.select(last_day(\"dt\"))`                  |\n",
    "| `trunc(col, fmt)`              | Utility        | Truncate date to month/year          | `df.select(trunc(\"dt\", \"MM\"))`               |\n",
    "| `date_trunc(fmt, ts)`          | Utility        | Truncate timestamp to hour/day/month | `df.select(date_trunc(\"hour\", \"ts\"))`        |\n",
    "| `from_utc_timestamp(ts, zone)` | Timezone       | Converts UTC to timezone             | `df.select(from_utc_timestamp(\"ts\", \"IST\"))` |\n",
    "| `to_utc_timestamp(ts, zone)`   | Timezone       | Converts timezone to UTC             | `df.select(to_utc_timestamp(\"ts\", \"IST\"))`   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e98385",
   "metadata": {},
   "source": [
    "# cuurent_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c076fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"date\").getOrCreate()\n",
    "\n",
    "df = spark.read.format(\"csv\")\\\n",
    "               .option(\"inferSchema\",True)\\\n",
    "               .option('header',True)\\\n",
    "               .load(\"C:/Git files/My git files/PySpark/files/products.csv\")\n",
    "\n",
    "df = df.withColumn(\"current_date\",current_date())\n",
    "df = df.withColumn(\"last_date\",last_day(col(\"current_date\")))\n",
    "df.select(\"current_date\",\"last_date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf11d6",
   "metadata": {},
   "source": [
    "# Date_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd8b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"week_after\",date_add('current_date',7))\n",
    "df.select(\"current_date\",\"last_date\",\"week_after\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c114a9",
   "metadata": {},
   "source": [
    "# Date_sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"week_before\",date_sub('current_date',7))\n",
    "df = df.withColumn(\"week_neg_before\",date_add('current_date',-7))\n",
    "df.select(\"current_date\",\"last_date\",\"week_after\",\"week_before\",\"week_neg_before\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3625963c",
   "metadata": {},
   "source": [
    "# Date Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01689e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"date_diff\",date_diff(\"week_after\",\"week_before\"))\n",
    "df.select(\"week_after\",\"week_before\",\"date_diff\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1745a3",
   "metadata": {},
   "source": [
    "# Date formate change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16f8037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----------+\n",
      "|week_before_formate_change|week_before|\n",
      "+--------------------------+-----------+\n",
      "|                23-11-2025| 2025-11-23|\n",
      "|                23-11-2025| 2025-11-23|\n",
      "|                23-11-2025| 2025-11-23|\n",
      "|                23-11-2025| 2025-11-23|\n",
      "|                23-11-2025| 2025-11-23|\n",
      "+--------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"week_before_formate_change\",date_format(\"week_before\",'dd-MM-yyyy'))\n",
    "df.select(\"week_before_formate_change\",\"week_before\").show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
